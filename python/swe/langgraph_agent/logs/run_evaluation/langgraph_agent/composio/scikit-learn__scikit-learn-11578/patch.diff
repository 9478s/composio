diff --git a/sklearn/linear_model/logistic.py b/sklearn/linear_model/logistic.py
index e4ea696..f36cabd 100644
--- a/sklearn/linear_model/logistic.py
+++ b/sklearn/linear_model/logistic.py
@@ -922,7 +922,10 @@ def _log_reg_scoring_path(X, y, train, test, pos_class=None, Cs=10,
         check_input=False, max_squared_sum=max_squared_sum,
         sample_weight=sample_weight)
 
-    log_reg = LogisticRegression(fit_intercept=fit_intercept)
+    log_reg = LogisticRegression(fit_intercept=fit_intercept, multi_class=multi_class,
+                                penalty=penalty, dual=dual, tol=tol, C=Cs[0],
+                                random_state=random_state, solver=solver,
+                                class_weight=class_weight, intercept_scaling=intercept_scaling)
 
     # The score method of Logistic Regression has a classes_ attribute.
     if multi_class == 'ovr':
diff --git a/sklearn/linear_model/tests/test_logistic.py b/sklearn/linear_model/tests/test_logistic.py
index 56be87f..60875bb 100644
--- a/sklearn/linear_model/tests/test_logistic.py
+++ b/sklearn/linear_model/tests/test_logistic.py
@@ -1260,3 +1260,43 @@ def test_warm_start_converge_LR():
         lr_ws.fit(X, y)
     lr_ws_loss = log_loss(y, lr_ws.predict_proba(X))
     assert_allclose(lr_no_ws_loss, lr_ws_loss, rtol=1e-5)
+
+def test_logistic_regression_cv_multinomial():
+    # Test that LogisticRegressionCV with multi_class='multinomial'
+    # gives consistent results with individually fitted LogisticRegression models
+    X, y = make_classification(n_samples=100, n_classes=3, n_informative=3,
+                               random_state=42)
+    
+    # Fit LogisticRegressionCV
+    clf_cv = LogisticRegressionCV(multi_class='multinomial', cv=5, random_state=42)
+    clf_cv.fit(X, y)
+    
+    # Get the best C value
+    best_C = clf_cv.C_[0]
+    
+    # Fit individual LogisticRegression models for each fold
+    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
+    scores_individual = []
+    
+    for train, test in cv.split(X, y):
+        clf = LogisticRegression(multi_class='multinomial', C=best_C, random_state=42)
+        clf.fit(X[train], y[train])
+        scores_individual.append(clf.score(X[test], y[test]))
+    
+    # Compare mean score of individual models with LogisticRegressionCV score
+    mean_score_individual = np.mean(scores_individual)
+    score_cv = clf_cv.score(X, y)
+    
+    assert_almost_equal(mean_score_individual, score_cv, decimal=3,
+                        err_msg="Inconsistent scores between LogisticRegressionCV "
+                                "and individual LogisticRegression models")
+
+    # Check that predict_proba gives consistent results
+    y_proba_cv = clf_cv.predict_proba(X)
+    clf_best = LogisticRegression(multi_class='multinomial', C=best_C, random_state=42)
+    clf_best.fit(X, y)
+    y_proba_best = clf_best.predict_proba(X)
+    
+    assert_allclose(y_proba_cv, y_proba_best, rtol=1e-3, atol=1e-3,
+                    err_msg="Inconsistent predict_proba between LogisticRegressionCV "
+                            "and best individual LogisticRegression model")
