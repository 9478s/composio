diff --git a/sklearn/linear_model/logistic.py b/sklearn/linear_model/logistic.py
index e4ea696..8a42792 100644
--- a/sklearn/linear_model/logistic.py
+++ b/sklearn/linear_model/logistic.py
@@ -922,7 +922,9 @@ def _log_reg_scoring_path(X, y, train, test, pos_class=None, Cs=10,
         check_input=False, max_squared_sum=max_squared_sum,
         sample_weight=sample_weight)
 
-    log_reg = LogisticRegression(fit_intercept=fit_intercept)
+    log_reg = LogisticRegression(fit_intercept=fit_intercept, multi_class=multi_class,
+                                solver=solver, penalty=penalty, dual=dual, tol=tol,
+                                random_state=random_state)
 
     # The score method of Logistic Regression has a classes_ attribute.
     if multi_class == 'ovr':
diff --git a/sklearn/linear_model/tests/test_logistic.py b/sklearn/linear_model/tests/test_logistic.py
index 56be87f..43bd4eb 100644
--- a/sklearn/linear_model/tests/test_logistic.py
+++ b/sklearn/linear_model/tests/test_logistic.py
@@ -1260,3 +1260,27 @@ def test_warm_start_converge_LR():
         lr_ws.fit(X, y)
     lr_ws_loss = log_loss(y, lr_ws.predict_proba(X))
     assert_allclose(lr_no_ws_loss, lr_ws_loss, rtol=1e-5)
+
+def test_log_reg_scoring_path_multi_class():
+    from sklearn.linear_model.logistic import _log_reg_scoring_path
+    X, y = make_classification(n_samples=100, n_classes=3, n_informative=3)
+    X_train, X_test = X[:80], X[80:]
+    y_train, y_test = y[:80], y[80:]
+    
+    # Test for 'ovr' multi_class
+    coefs, Cs, scores, _ = _log_reg_scoring_path(X, y, [range(80)], [range(80, 100)],
+                                                 Cs=[1], scoring='neg_log_loss',
+                                                 fit_intercept=True, multi_class='ovr')
+    lr_ovr = LogisticRegression(multi_class='ovr', C=1)
+    lr_ovr.fit(X_train, y_train)
+    ovr_score = -log_loss(y_test, lr_ovr.predict_proba(X_test))
+    assert_almost_equal(scores[0], ovr_score, decimal=4)
+
+    # Test for 'multinomial' multi_class
+    coefs, Cs, scores, _ = _log_reg_scoring_path(X, y, [range(80)], [range(80, 100)],
+                                                 Cs=[1], scoring='neg_log_loss',
+                                                 fit_intercept=True, multi_class='multinomial')
+    lr_multi = LogisticRegression(multi_class='multinomial', C=1)
+    lr_multi.fit(X_train, y_train)
+    multi_score = -log_loss(y_test, lr_multi.predict_proba(X_test))
+    assert_almost_equal(scores[0], multi_score, decimal=4)
