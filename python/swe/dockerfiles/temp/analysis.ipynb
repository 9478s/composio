{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from swebench import MAP_VERSION_TO_INSTALL, get_eval_refs, get_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "dataset = \"princeton-nlp/SWE-bench_Verified\"\n",
    "task_instances = get_eval_refs(data_path_or_name=dataset)\n",
    "print(len(task_instances))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'django__django': 231,\n",
       "         'sympy__sympy': 75,\n",
       "         'sphinx': 44,\n",
       "         'matplotlib__matplotlib': 34,\n",
       "         'scikit': 32,\n",
       "         'astropy__astropy': 22,\n",
       "         'pydata__xarray': 22,\n",
       "         'pytest': 19,\n",
       "         'pylint': 10,\n",
       "         'psf__requests': 8,\n",
       "         'mwaskom__seaborn': 2,\n",
       "         'pallets__flask': 1})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter([x.split(\"-\")[0] for x in task_instances.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_save_dir = f\"../../temp/{dataset.split('/')[-1]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_key = next(iter(task_instances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = task_instances[instance_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_json(path: Path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_json(data, path: Path):\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for instance_key in task_instances:\n",
    "    Path(dataset_save_dir, instance_key).mkdir(parents=True, exist_ok=True)\n",
    "    instance = task_instances[instance_key]\n",
    "    metadata = {\n",
    "        \"repo\": instance['repo'],\n",
    "        'instance_id': instance['instance_id'],\n",
    "        'base_commit': instance['base_commit'],\n",
    "        'created_at': instance['created_at'],\n",
    "        'version': instance['version'],\n",
    "    }\n",
    "    with open(Path(dataset_save_dir, instance_key, \"patch.txt\"), 'w') as handle:\n",
    "        handle.write(instance['patch'])\n",
    "    with open(Path(dataset_save_dir, instance_key, \"test_patch.txt\"), 'w') as handle:\n",
    "        handle.write(instance['test_patch'])\n",
    "    with open(Path(dataset_save_dir, instance_key, \"problem_statement.txt\"), 'w') as handle:\n",
    "        handle.write(instance['problem_statement'])\n",
    "    with open(Path(dataset_save_dir, instance_key, \"hints_text.txt\"), 'w') as handle:\n",
    "        handle.write(instance['hints_text'])\n",
    "    \n",
    "    save_json(metadata, Path(dataset_save_dir, instance_key, \"metadata.json\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instances = random.sample(sorted(task_instances), 25)\n",
    "test_instances = ['sympy__sympy-24539',\n",
    " 'django__django-16493',\n",
    " 'sphinx-doc__sphinx-8595',\n",
    " 'django__django-14373',\n",
    " 'sympy__sympy-22914',\n",
    " 'django__django-16255',\n",
    " 'sympy__sympy-16766',\n",
    " 'sympy__sympy-20801',\n",
    " 'django__django-13590',\n",
    " 'django__django-7530',\n",
    " 'scikit-learn__scikit-learn-11578',\n",
    " 'django__django-12143',\n",
    " 'pydata__xarray-4966',\n",
    " 'django__django-11603',\n",
    " 'django__django-16612',\n",
    " 'django__django-13741',\n",
    " 'django__django-14089',\n",
    " 'django__django-10880',\n",
    " 'django__django-15467',\n",
    " 'django__django-14500',\n",
    " 'django__django-13810',\n",
    " 'sympy__sympy-21847',\n",
    " 'scikit-learn__scikit-learn-10297',\n",
    " 'django__django-13820',\n",
    " 'sympy__sympy-24066']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in test_instances:\n",
    "    source_path = os.path.join(\"../../temp/SWE-bench_Verified\", file_name)\n",
    "    destination_path = os.path.join(\"../../temp/test\", file_name)\n",
    "    shutil.copytree(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in os.listdir(\"../../temp/SWE-bench_Verified\"):\n",
    "    if file_name in test_instances: continue\n",
    "    source_path = os.path.join(\"../../temp/SWE-bench_Verified\", file_name)\n",
    "    destination_path = os.path.join(\"../../temp/train\", file_name)\n",
    "    shutil.copytree(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "for files in glob.glob(\"../generated/sphinx-doc__sphinx/*/Dockerfile\"):\n",
    "    content = open(files).read()\n",
    "    content = \"\\n\".join([line for line in content.splitlines() if \"sed\" not in line])\n",
    "    open(files, \"w\").write(content)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM composio/swe:py3.9\n",
      "\n",
      "# Switch user\n",
      "USER user\n",
      "\n",
      "# Go to user dir\n",
      "WORKDIR /home/user\n",
      "\n",
      "# Clone github repository\n",
      "RUN git config --global http.postBuffer 157286400 && git config --global --add safe.directory /home/user/sphinx && git clone --depth 1 https://github.com/sphinx-doc/sphinx\n",
      "\n",
      "# Set repository as workdir\n",
      "WORKDIR /home/user/sphinx\n",
      "\n",
      "# Fetch the base commit\n",
      "RUN git fetch --depth 1 origin 4b452338f914d4f6b54704222d70ae8a746e3db5\n",
      "\n",
      "# Checkout to base commit\n",
      "RUN git checkout 4b452338f914d4f6b54704222d70ae8a746e3db5\n",
      "\n",
      "WORKDIR /home/user\n",
      "\n",
      "RUN mkdir -p /home/user/.composio/tmp\n",
      "COPY deeplake /home/user/.composio/tmp/sphinx/deeplake\n",
      "COPY fqdn_cache.json /home/user/.composio/tmp/sphinx\n",
      "\n",
      "# Install dependecies\n",
      "RUN /home/user/.dev/bin/python -m pip install \"tox\" || echo \"$?\"\n",
      "\n",
      "# Pre install\n",
      "\n",
      "# Install package\n",
      "RUN /home/user/.dev/bin/python -m pip install -e .[test] || echo \"$?\"\n",
      "\n",
      "ENV HOME=/home/user/\n",
      "\n",
      "WORKDIR /home/user/sphinx\n",
      "\n",
      "# Switch to root\n",
      "USER root\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join([line for line in content.splitlines() if \"sed\" not in line]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-PN9waRBr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
